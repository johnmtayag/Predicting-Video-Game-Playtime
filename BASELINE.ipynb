{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4de33b3-b307-469a-b4b3-68de6838659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "import string\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm, colors\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "528eb567-f457-418b-9c2b-9830f82ae52b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### EVALUATION / METRICS\n",
    "######################################\n",
    "def convert_to_np_array(A):\n",
    "    \"\"\"\n",
    "    If A is not already an array, convert it to an array\n",
    "    \"\"\"\n",
    "    if not isinstance(A, np.ndarray): return np.array(A)\n",
    "    else: return A\n",
    "\n",
    "def get_MSE(A, B):\n",
    "    \"\"\"\n",
    "    Given list A and list B:\n",
    "    Return the mean squared error between A and B\n",
    "    \"\"\"\n",
    "    return np.mean((convert_to_np_array(A) - convert_to_np_array(B))**2)\n",
    "\n",
    "def inner(A, B):\n",
    "    \"\"\"\n",
    "    Return the dot product between list A and list B\n",
    "    \"\"\"\n",
    "    return np.dot(convert_to_np_array(A), convert_to_np_array(B))\n",
    "\n",
    "def get_SSE(A, B):\n",
    "    \"\"\"\n",
    "    Given list A and list B:\n",
    "    Return the sum of squared errors between A and B\n",
    "    \"\"\"\n",
    "    return np.sum((convert_to_np_array(A) - convert_to_np_array(B))**2)\n",
    "\n",
    "def get_MAE(A,B):\n",
    "    \"\"\"\n",
    "    Given list A and list B:\n",
    "    Return the mean absolute error between A and B\n",
    "    \"\"\"\n",
    "\n",
    "    errors = [abs(a - b) for a,b in zip(A,B)]\n",
    "    return sum(errors) / len(errors)\n",
    "\n",
    "def get_SE(A,B):\n",
    "    \"\"\"\n",
    "    Given list A and list B:\n",
    "    Return the squared error between each element\n",
    "    \"\"\"\n",
    "    return (convert_to_np_array(A) - convert_to_np_array(B))**2\n",
    "\n",
    "def get_accuracy(A,B):\n",
    "    \"\"\"\n",
    "    Given list A and list B:\n",
    "    Return the accuracy\n",
    "    \"\"\"\n",
    "    return np.sum(convert_to_np_array(A) == convert_to_np_array(B)) / len(A)\n",
    "\n",
    "def get_BER(y_actual, y_predicted):\n",
    "    \"\"\"\n",
    "    \"Return the balanced error rate between positive (1) and negative(0) instances\n",
    "    \"\"\"\n",
    "\n",
    "    TP, FP, TN, FN = 0, 0, 0, 0\n",
    "    n_pos, n_neg = 0, 0\n",
    "    for actual, pred in zip(y_actual, y_predicted):\n",
    "        if actual==1:\n",
    "            n_pos += 1\n",
    "            if actual==pred:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        else:\n",
    "            n_neg += 1\n",
    "            if actual==pred:\n",
    "                TN += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "    FPR = FP / (FP + TN)\n",
    "    FNR = FN / (FN + TP)\n",
    "        \n",
    "    return (1/2) * (FPR + FNR)\n",
    "\n",
    "def get_errorMetrics_binary(y_actual, y_predicted, beta=1):\n",
    "    \"\"\"\n",
    "    Return a set of error metrics between positive (1) and negative (0) instances\n",
    "    This is valid for a binary class case\n",
    "    Return a dictionary containing all calculated values\n",
    "    \"\"\"\n",
    "\n",
    "    output = {}\n",
    "    TP, FP, TN, FN = 0, 0, 0, 0\n",
    "    n_pos, n_neg = 0, 0\n",
    "    for actual, pred in zip(y_actual, y_predicted):\n",
    "        if actual==1:\n",
    "            n_pos += 1\n",
    "            if actual==pred:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        else:\n",
    "            n_neg += 1\n",
    "            if actual==pred:\n",
    "                TN += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "    ###\n",
    "    TPR, FNR = TP / n_pos, FN / n_pos\n",
    "    FPR, TNR = FP / n_neg, TN / n_neg\n",
    "    prec = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    output[\"TP\"], output[\"FP\"], output[\"TN\"], output[\"FN\"] = TP, FP, TN, FN\n",
    "    output[\"TPR\"], output[\"FPR\"], output[\"FNR\"], output[\"TNR\"] = TPR, FPR, FNR, TNR\n",
    "    output[\"precision\"], output[\"recall\"] = prec, recall\n",
    "    output[\"BER\"] = (1/2) * (FPR + FNR)\n",
    "    output[f\"F{beta}_Score\"] = (1 + beta**2) * (prec * recall) / ((beta**2)*prec + recall)\n",
    "    output[\"F_Score\"] = 2 * (prec * recall) / (prec + recall)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffaeb450-6a88-4200-9501-3a52ce2902ae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### SIMILARITY FUNCTIONS\n",
    "######################################\n",
    "def jaccard_sim(A,B):\n",
    "    \"\"\"\n",
    "    Return the Jaccard similarity between list A and list B\n",
    "    \"\"\"\n",
    "    if not isinstance(A, set): A = set(A)\n",
    "    if not isinstance(B, set): B = set(B)\n",
    "    n_intersect = len(A.intersection(B))\n",
    "    n_union = len(A.union(B))\n",
    "    if n_union == 0: return 0\n",
    "\n",
    "    return n_intersect / n_union\n",
    "\n",
    "def cosine_sim_binary(A,B, denom_over_all=True):\n",
    "    \"\"\"\n",
    "    Return the cosine similarity between set A and set B (Binary interactions)\n",
    "    \"\"\"\n",
    "    if not isinstance(A, set): A = set(A)\n",
    "    if not isinstance(B, set): B = set(B)\n",
    "    n_intersect = len(A.intersection(B))\n",
    "\n",
    "    if denom_over_all:\n",
    "        total_interactions = np.sqrt(len(A) * len(B))\n",
    "    else:\n",
    "        total_interactions = n_intersect\n",
    "    if total_interactions == 0:\n",
    "        return 0\n",
    "    return n_intersect / total_interactions\n",
    "\n",
    "############# Design structures to record shared items\n",
    "def cosine_sim(x_tuple, y_tuple, denom_over_all):\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity between lists x and y\n",
    "    Input are lists of tuples: [(id1, rating), (id2, rating), ...]\n",
    "    \"\"\"\n",
    "    # Get shared items\n",
    "    x_ids, y_ids = set(), set()\n",
    "    x_ratings, y_ratings = [], []\n",
    "    shared_ratings_x, shared_ratings_y = [], []\n",
    "    shared_tuples_x, shared_tuples_y = [], []\n",
    "    for tuple in x_tuple:\n",
    "        x_ids.add(tuple[0])\n",
    "        x_ratings.append(tuple[1])\n",
    "    for tuple in y_tuple:\n",
    "        y_ids.add(tuple[0])\n",
    "        y_ratings.append(tuple[1])\n",
    "    shared_ids = x_ids.intersection(y_ids)\n",
    "\n",
    "    shared_tuples_x = [tuple for tuple in x_tuple if tuple[0] in shared_ids]\n",
    "    shared_tuples_x.sort()\n",
    "    shared_tuples_y = [tuple for tuple in y_tuple if tuple[0] in shared_ids]\n",
    "    shared_tuples_y.sort()\n",
    "    shared_ratings_x = [tuple[1] for tuple in shared_tuples_x]\n",
    "    shared_ratings_y = [tuple[1] for tuple in shared_tuples_y]\n",
    "\n",
    "    if denom_over_all:\n",
    "        # Use all items in the denominator\n",
    "        x_norm = np.sum([xi**2 for xi in x_ratings])\n",
    "        y_norm = np.sum([yi**2 for yi in y_ratings])\n",
    "    else:\n",
    "        # Only use shared items in the denominator\n",
    "        x_norm = np.sum([xi**2 for xi in shared_ratings_x])\n",
    "        y_norm = np.sum([yi**2 for yi in shared_ratings_y])\n",
    "    denom = np.sqrt(x_norm) * np.sqrt(y_norm)\n",
    "\n",
    "    if denom == 0: return 0\n",
    "    numer = sum([xi*yi for xi,yi in zip(shared_ratings_x, shared_ratings_y)])\n",
    "\n",
    "    return numer / denom\n",
    "\n",
    "def pearson_sim(x_tuple, y_tuple):\n",
    "    \"\"\"\n",
    "    Calculate the pearson similarity between lists x and y\n",
    "    Input are lists of tuples: [(id1, rating), (id2, rating), ...]\n",
    "    Unlike Cosine sim, ONLY shared items can be considered\n",
    "    If id1 or id2 is not in the relevant training data structure, use meanValue as its respective mean\n",
    "    \"\"\"\n",
    "    # Unpack averages\n",
    "    x_avgs = {tuple[0][0]:tuple[1] for tuple in x_tuple}\n",
    "    y_avgs = {tuple[0][0]:tuple[1] for tuple in y_tuple}\n",
    "    # Get shared items\n",
    "    shared_ratings_x, shared_ratings_y = [], []\n",
    "    shared_tuples_x, shared_tuples_y = [], []\n",
    "    x_ids = {tuple[0][0] for tuple in x_tuple}\n",
    "    y_ids = {tuple[0][0] for tuple in y_tuple}\n",
    "    shared_ids = x_ids.intersection(y_ids)\n",
    "\n",
    "    shared_tuples_x = [tuple[0] for tuple in x_tuple if tuple[0][0] in shared_ids]\n",
    "    shared_tuples_x.sort()\n",
    "    shared_tuples_y = [tuple[0] for tuple in y_tuple if tuple[0][0] in shared_ids]\n",
    "    shared_tuples_y.sort()\n",
    "    shared_ratings_x = [tuple[1] - x_avgs[tuple[0]] for tuple in shared_tuples_x] ### Pearson --> Subtract the mean from each value\n",
    "    shared_ratings_y = [tuple[1] - y_avgs[tuple[0]] for tuple in shared_tuples_y]\n",
    "\n",
    "    # Only use shared items in the denominator\n",
    "    x_norm = np.sum([xi**2 for xi in shared_ratings_x])\n",
    "    y_norm = np.sum([yi**2 for yi in shared_ratings_y])\n",
    "    denom = np.sqrt(x_norm * y_norm)\n",
    "\n",
    "    if denom == 0: return 0\n",
    "    numer = sum([xi*yi for xi,yi in zip(shared_ratings_x, shared_ratings_y)])\n",
    "\n",
    "    return numer / denom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "963b42d1-a6ab-46e6-82a5-f6dd1827f5b6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### COLLABORATIVE FILTERING\n",
    "######################################\n",
    "\n",
    "\n",
    "def predictValue_bySim_devFromMean(user_id, item_id, sim_func, type, meanValue, value_bounds=None, denom_over_all=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Predict some value (e.g., rating) that the user (user_id) will give an item (item_id) based on\n",
    "    the input simularity function (sim_func). However, instead of predicting the rating directly,\n",
    "    predict the deviation from the global mean rating\n",
    "\n",
    "    # Necessary Data Structures --> These are built using training data ONLY\n",
    "    itemsPerUser: A dictionary containing the list of items each user interacted with and corresponding values\n",
    "       ex: itemsPerUser[user1] = [(item1, 2), (item3, 1), (item5, 5), ...]\n",
    "    usersPerItem: A dictionary containing the list of users that interacted with each item and corresponding values\n",
    "       ex: usersPerItem[item1] = [(user1, 2), (user4, 2), (user27, 2), ...]\n",
    "    itemAverages: A dictionary containing the mean value for each item\n",
    "    userAverages: A dictionary containing the mean value for each user\n",
    "    #--- value_bounds: The min/max values that can be outputted as typically there's a scale (e.g., 1-5 stars)\n",
    "    #--- meanValue: The mean of all values in valueDict.values()\n",
    "\n",
    "    # Gathering similarity weights:\n",
    "    If type==0:\n",
    "       # Predict the rating as a weighted sum of ratings that user_id has given to other items #\n",
    "       For each item (item_id2) that user_id has interacted with (except for item_id):\n",
    "          Calculate item_id2's similarity to item_id based on shared user interactions\n",
    "          Track these values as similarity weights\n",
    "    else:\n",
    "       # Predict the rating as a weighted sum of ratings that other users have given to item_id #\n",
    "       For each user (user_id2) that have interacted with item_id (except for user_id):\n",
    "          Calculate user_id2's similarity to user_id based on shared item interactions\n",
    "          Track these values as similarity weights\n",
    "    \"\"\"\n",
    "    # Edge case 1: Return global mean value if user_id or item_id are unseen\n",
    "    if (user_id not in itemsPerUser) or (item_id not in usersPerItem): return meanValue\n",
    "    # Initialize variables\n",
    "    if denom_over_all is None: denom_over_all = True\n",
    "    if value_bounds is None: value_bounds = (-np.inf, np.inf)\n",
    "    values, similarities = [], []\n",
    "\n",
    "    if type == \"item\":\n",
    "        # Predict the rating as a weighted combination of how other items rated by user_id were\n",
    "        # rated by similar users\n",
    "        # if user_id not in userAverages: return meanValue # Skip keys that are not in the dict\n",
    "        avg_value = userAverages[user_id]\n",
    "        for user_id2,value in usersPerItem[item_id]:\n",
    "            if user_id2 == user_id: continue\n",
    "            # if user_id2 not in userAverages: continue  # Skip keys that are not in the dict\n",
    "            if sim_func == jaccard_sim:\n",
    "                simset_user_id = {tuple[0] for tuple in itemsPerUser[user_id] if tuple[0] != item_id}\n",
    "                simset_user_id2 = {tuple[0] for tuple in itemsPerUser[user_id2] if tuple[0] != item_id}\n",
    "                similarities.append(sim_func(simset_user_id, simset_user_id2))\n",
    "            elif sim_func == cosine_sim_binary:\n",
    "                if denom_over_all is None: denom_over_all = True\n",
    "                simset_user_id = {tuple[0] for tuple in itemsPerUser[user_id] if tuple[0] != item_id}\n",
    "                simset_user_id2 = {tuple[0] for tuple in itemsPerUser[user_id2] if tuple[0] != item_id}\n",
    "                similarities.append(sim_func(simset_user_id, simset_user_id2, denom_over_all))\n",
    "            elif sim_func == cosine_sim:\n",
    "                if denom_over_all is None: denom_over_all = True\n",
    "                simset_user_id = {tuple for tuple in itemsPerUser[user_id] if tuple[0] != item_id}\n",
    "                simset_user_id2 = {tuple for tuple in itemsPerUser[user_id2] if tuple[0] != item_id}\n",
    "                similarities.append(sim_func(simset_user_id, simset_user_id2, denom_over_all))\n",
    "            elif sim_func == pearson_sim:\n",
    "                simset_user_id = {(tuple, itemAverages[tuple[0]]) for tuple in itemsPerUser[user_id] if tuple[0] != item_id}\n",
    "                simset_user_id2 = {(tuple, itemAverages[tuple[0]]) for tuple in itemsPerUser[user_id2] if tuple[0] != item_id}\n",
    "                similarities.append(sim_func(simset_user_id, simset_user_id2))\n",
    "            else:\n",
    "                # Sim function not programmed\n",
    "                print(\"Invalid sim_func\")\n",
    "                return None\n",
    "            values.append(value - userAverages[user_id2])\n",
    "    else:\n",
    "        # Predict user_id's rating of item_id based on a weighted combination of how other users who\n",
    "        # rated item_id rated other items\n",
    "        # if item_id not in itemAverages: return meanValue # Skip keys that are not in the dict\n",
    "        avg_value = itemAverages[item_id]\n",
    "        for item_id2,value in itemsPerUser[user_id]:\n",
    "            if item_id2 == item_id: continue\n",
    "            # if item_id2 not in itemAverages: continue # Skip keys that are not in the dict\n",
    "            if sim_func == jaccard_sim:\n",
    "                simset_item_id = {tuple[0] for tuple in usersPerItem[item_id] if tuple[0] != user_id}\n",
    "                simset_item_id2 = {tuple[0] for tuple in usersPerItem[item_id2] if tuple[0] != user_id}\n",
    "                similarities.append(sim_func(simset_item_id, simset_item_id2))\n",
    "            elif sim_func == cosine_sim_binary:\n",
    "                if denom_over_all is None: denom_over_all = True\n",
    "                simset_item_id = {tuple[0] for tuple in usersPerItem[item_id] if tuple[0] != user_id}\n",
    "                simset_item_id2 = {tuple[0] for tuple in usersPerItem[item_id2] if tuple[0] != user_id}\n",
    "                similarities.append(sim_func(simset_item_id, simset_item_id2, denom_over_all))\n",
    "            elif sim_func == cosine_sim:\n",
    "                if denom_over_all is None: denom_over_all = True\n",
    "                simset_item_id = {tuple for tuple in usersPerItem[item_id] if tuple[0] != user_id}\n",
    "                simset_item_id2 = {tuple for tuple in usersPerItem[item_id2] if tuple[0] != user_id}\n",
    "                similarities.append(sim_func(simset_item_id, simset_item_id2, denom_over_all))\n",
    "            elif sim_func == pearson_sim:\n",
    "                simset_item_id = {(tuple, userAverages[tuple[0]]) for tuple in usersPerItem[item_id] if tuple[0] != user_id}\n",
    "                simset_item_id2 = {(tuple, userAverages[tuple[0]]) for tuple in usersPerItem[item_id2] if tuple[0] != user_id}\n",
    "                similarities.append(sim_func(simset_item_id, simset_item_id2))\n",
    "            else:\n",
    "                # Sim function not programmed\n",
    "                print(\"Invalid sim_func\")\n",
    "                return None\n",
    "            values.append(value - itemAverages[item_id2])\n",
    "    # Edge case 2: Return global mean value if there are no similar items\n",
    "    if np.sum(similarities) == 0: return meanValue\n",
    "\n",
    "    numerator = np.sum([value*sim for value,sim in zip(values, similarities)])\n",
    "    denominator = np.sum(similarities)\n",
    "    output = avg_value + (numerator / denominator)\n",
    "    if output < value_bounds[0]: return value_bounds[0]\n",
    "    if output > value_bounds[1]: return value_bounds[1]\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77c2fbe9-6f5a-4398-a0f4-f7884d1ebadd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### LATENT FACTOR MODEL\n",
    "######################################\n",
    "def initialize_params(ratingDict, itemsPerUser, usersPerItem, k, init_bounds):\n",
    "    \"\"\"\n",
    "    Return the initialized parameters\n",
    "    \"\"\"\n",
    "    user_count, item_count = len(itemsPerUser), len(usersPerItem)\n",
    "    lower, upper = init_bounds\n",
    "    alpha = np.mean([i for i in ratingDict.values()])\n",
    "    user_bias = dict(zip(users, [random.uniform(lower,upper) for i in range(user_count)]))\n",
    "    item_bias = dict(zip(items, [random.uniform(lower,upper) for i in range(item_count)]))\n",
    "    user_gamma = dict(zip(users, [[random.uniform(lower,upper) for ki in range(k)] for i in range(user_count)]))\n",
    "    item_gamma = dict(zip(items, [[random.uniform(lower,upper) for ki in range(k)] for i in range(item_count)]))\n",
    "\n",
    "    return (alpha, user_bias, item_bias, user_gamma, item_gamma)\n",
    "\n",
    "def get_lfm_defaults(theta):\n",
    "    \"\"\"\n",
    "    Calculate average values/vectors to use as default values for the latent factor predictions\n",
    "    \"\"\"\n",
    "    alpha, user_bias, item_bias, user_gamma, item_gamma = theta\n",
    "    avg_params = {}\n",
    "    avg_params[\"avg_user_bias\"] = np.mean(np.array([i for i in user_bias.values()]))\n",
    "    avg_params[\"avg_item_bias\"] = np.mean(np.array([i for i in item_bias.values()]))\n",
    "    avg_params[\"avg_user_gamma\"] = np.mean(np.array([values for values in user_gamma.values()]), axis=0)\n",
    "    avg_params[\"avg_item_gamma\"] = np.mean(np.array([values for values in item_gamma.values()]), axis=0)\n",
    "\n",
    "    return avg_params\n",
    "\n",
    "def predict_latent_factor(u_id, item_id, theta, value_bounds = None, avg_params = None):\n",
    "    \"\"\"\n",
    "    Return the prediction based on u_id and item_id\n",
    "    If u_id is not in itemsPerUser --> Use the average gamma vector\n",
    "    Repeat this process for if item_id is not in usersPerItem\n",
    "\n",
    "    Bound the output by the min and max of the possible values \n",
    "    (ex: Model shouldn't exceed 5 when the scale is 5)\n",
    "    \"\"\"\n",
    "    if value_bounds is None: value_bounds = (-np.inf, np.inf)\n",
    "    alpha, user_bias, item_bias, user_gamma, item_gamma = theta\n",
    "    for i,(gamma_vec) in enumerate(user_gamma.values()):\n",
    "        if i > 0: break\n",
    "        k = len(gamma_vec)\n",
    "\n",
    "    if u_id in user_bias: u_bias = user_bias[u_id]\n",
    "    else:\n",
    "        if (avg_params is not None) and (item_id in item_bias): u_bias = avg_params[\"avg_user_bias\"]\n",
    "        else: u_bias = 0\n",
    "\n",
    "    if item_id in item_bias: i_bias = item_bias[item_id]\n",
    "    else:\n",
    "        if (avg_params is not None) and (u_id in user_bias): i_bias = avg_params[\"avg_item_bias\"]\n",
    "        else: i_bias = 0\n",
    "\n",
    "    if u_id in user_gamma: u_gamma = np.array(user_gamma[u_id])\n",
    "    else:\n",
    "        if (avg_params is not None) and (item_id in item_gamma): u_gamma = avg_params[\"avg_user_gamma\"]\n",
    "        else: u_gamma = [0]*k\n",
    "\n",
    "    if item_id in item_gamma: i_gamma = np.array(item_gamma[item_id])\n",
    "    else:\n",
    "        if (avg_params is not None) and (u_id in user_gamma): i_gamma = avg_params[\"avg_item_gamma\"]\n",
    "        else: i_gamma = [0]*k\n",
    "\n",
    "    value = alpha + u_bias + i_bias + np.dot(u_gamma, i_gamma)\n",
    "    if value < value_bounds[0]: return value_bounds[0]\n",
    "    if value > value_bounds[1]: return value_bounds[1]\n",
    "\n",
    "    return value\n",
    "\n",
    "def get_cost(theta, lambda_bias, lambda_gamma, Xtrain, ytrain, k, value_bounds=None):\n",
    "    \"\"\"\n",
    "    Calculate the cost for the given theta parameters\n",
    "    Xtrain must be of form [(user, item), (user, item), ...]\n",
    "    \"\"\"\n",
    "    alpha, user_bias, item_bias, user_gamma, item_gamma = theta\n",
    "    # Predict using the current theta values\n",
    "    predictions = np.array([predict_latent_factor(tuple[0], tuple[1], theta, value_bounds) for tuple in Xtrain])\n",
    "    # Calculate SSE + regularization\n",
    "    cost = get_SSE(predictions, ytrain)\n",
    "    cost += lambda_bias * np.sum(np.array([val**2 for val in user_bias.values()]))\n",
    "    cost += lambda_bias * np.sum(np.array([val**2 for val in item_bias.values()]))\n",
    "    cost += lambda_gamma * np.sum(np.array([inner(gam, gam) for gam in user_gamma.values()]))\n",
    "    cost += lambda_gamma * np.sum(np.array([inner(gam, gam) for gam in item_gamma.values()]))\n",
    "\n",
    "    return cost\n",
    "\n",
    "def update_params(theta, lambda_bias, lambda_gamma, Xtrain, ytrain, fix_value):\n",
    "    \"\"\"\n",
    "    Update parameters based on how well they predict in their CURRENT states\n",
    "    Coordinate descent instead of gradient descent for faster convergence\n",
    "    ###\n",
    "    Latent factor model\n",
    "         Fix user_gamma --> iterate and update alpha, user_bias, item_gamma\n",
    "         Fix item_gamma --> iterate and update alpha, user_bias, user_gamma\n",
    "    Fix user_gamma... Fix item_gamma...\n",
    "    Repeat the above until model have converged\n",
    "    \"\"\"\n",
    "    alpha, user_bias, item_bias, user_gamma, item_gamma = theta\n",
    "    # Iterate through the alpha and bias params\n",
    "    if (fix_value == 0) or (fix_value == 4):\n",
    "        # Calculate the new alpha\n",
    "        alpha_sum = 0\n",
    "        for tuple, rating in zip(Xtrain, ytrain):\n",
    "            u_id, item_id = tuple\n",
    "            alpha_sum += (rating - (user_bias[u_id] + item_bias[item_id] + inner(user_gamma[u_id], item_gamma[item_id])))\n",
    "        dalpha = alpha_sum / N\n",
    "        alpha = dalpha.copy()\n",
    "    elif (fix_value == 1) or (fix_value == 5):\n",
    "        # Calculate the new user bias\n",
    "        duser_bias = {}\n",
    "        for u_id in users:\n",
    "            user_sum = 0\n",
    "            users_item_count = len(itemsPerUser[u_id])\n",
    "            for tuple in itemsPerUser[u_id]:\n",
    "                item_id, rating = tuple\n",
    "                user_sum += (rating - (alpha + item_bias[item_id] + inner(user_gamma[u_id], item_gamma[item_id])))\n",
    "            duser_bias[u_id] = (user_sum * (1 / (users_item_count + lambda_bias)))\n",
    "        user_bias = duser_bias.copy()\n",
    "    elif (fix_value == 2) or (fix_value == 6):\n",
    "        # Calculate the new item bias\n",
    "        ditem_bias = {}\n",
    "        for item_id in items:\n",
    "            item_sum = 0\n",
    "            items_user_count = len(usersPerItem[item_id])\n",
    "            for tuple in usersPerItem[item_id]:\n",
    "                u_id, rating = tuple\n",
    "                item_sum += (rating - (alpha + user_bias[u_id] + inner(user_gamma[u_id], item_gamma[item_id])))\n",
    "            ditem_bias[item_id] = (item_sum * (1 / (items_user_count + lambda_bias)))\n",
    "        item_bias = ditem_bias.copy()\n",
    "    elif fix_value == 3:\n",
    "        # Calculate the new user gamma\n",
    "        duser_gamma = {}\n",
    "        for u_id in users:\n",
    "            user_sums = [0] * k\n",
    "            i_gamma_k_sqrd_sums = [0] * k\n",
    "            users_item_count = len(itemsPerUser[u_id])\n",
    "            for tuple in itemsPerUser[u_id]:\n",
    "                item_id, rating = tuple\n",
    "                # Update each user's gamma value\n",
    "                for ki in range(k):\n",
    "                    i_gamma_k = item_gamma[item_id][ki]\n",
    "                    i_gamma_k_sqrd_sums[ki] += i_gamma_k**2\n",
    "                    user_sums[ki] = i_gamma_k * (rating - (alpha + user_bias[u_id] + item_bias[item_id]))\n",
    "            duser_gamma[u_id] = [user_sums[ki] * (1 / (users_item_count*i_gamma_k_sqrd_sums[ki] + lambda_gamma)) for ki in range(k)]\n",
    "        user_gamma = duser_gamma.copy()\n",
    "    elif fix_value == 7:\n",
    "         # Calculate the new item gamma\n",
    "        ditem_gamma = {}\n",
    "        for item_id in items:\n",
    "            item_sums = [0] * k\n",
    "            u_gamma_k_sqrd_sums = [0] * k\n",
    "            items_user_count = len(usersPerItem[item_id])\n",
    "            for tuple in usersPerItem[item_id]:\n",
    "                u_id, rating = tuple\n",
    "                # Update each item's gamma value\n",
    "                for ki in range(k):\n",
    "                    u_gamma_k = user_gamma[u_id][ki]\n",
    "                    u_gamma_k_sqrd_sums[ki] += u_gamma_k**2\n",
    "                    item_sums[ki] = u_gamma_k * (rating - (alpha + user_bias[u_id] + item_bias[item_id]))\n",
    "            ditem_gamma[item_id] = [item_sums[ki] * (1 / (items_user_count*u_gamma_k_sqrd_sums[ki] + lambda_gamma)) for ki in range(k)]\n",
    "        item_gamma = ditem_gamma.copy()\n",
    "\n",
    "    return (alpha, user_bias, item_bias, user_gamma, item_gamma)\n",
    "\n",
    "def fit_parameters(Xtrain, ytrain, theta, ep=0.0005, iter_limit=200, quiet=True, value_bounds=(-np.inf, np.inf), check_every=10, **kwargs):\n",
    "    \"\"\"\n",
    "    Fit the parameters until convergence (when difference in cost is less than ep)\n",
    "    Arguments packed into **kwargs:\n",
    "    lambda_bias --> Regularization parameter for the user/item biases\n",
    "    lambda_gamma --> Regularization parameter for the user/item gamma matrix\n",
    "    k --> Number of latent parameters to use per user/item vector\n",
    "    ep --> The threshold for early stopping between mse checks\n",
    "    iter_limit --> The maximum number of iterations allowed\n",
    "    value_bounds --> The expected range of values expected to be outputted by the model\n",
    "    check_every --> Calculate the cost/mse whenever iter_count is perfectly divisible by check_every (ex: check_every=10 means check every 10 iterations)\n",
    "    \"\"\"\n",
    "    last_mse, last_cost = np.inf, np.inf\n",
    "    best_params = [theta, last_mse, last_cost]\n",
    "\n",
    "    iter_count = 0\n",
    "    while True:\n",
    "        # Track iteration count as well as which parameter to update (fix_value)\n",
    "        iter_count += 1\n",
    "        fix_value = (iter_count - 1) % 8\n",
    "\n",
    "        # Update theta\n",
    "        theta = update_params(theta, lambda_bias, lambda_gamma, Xtrain, ytrain, fix_value)\n",
    "\n",
    "        # Every few iterations, check cost and mse\n",
    "        if (iter_count % check_every == 0):\n",
    "            cost = get_cost(theta, lambda_bias, lambda_gamma, Xtrain, ytrain, k, value_bounds)\n",
    "            predictions = np.array([predict_latent_factor(tuple[0], tuple[1], theta, value_bounds) for tuple in Xtrain])\n",
    "            mse = get_MSE(predictions, ytrain)\n",
    "            if not quiet:\n",
    "                print(f\"Iteration {iter_count}: Cost = {cost}, Train MSE = {mse}\")\n",
    "            ### Check cost/mse\n",
    "            # Save current params as best_params if the mse is less than the last mse\n",
    "            if mse < best_params[1]:\n",
    "                best_params = [theta, mse, cost]\n",
    "                # If the difference in cost is less than ep, stop iterating\n",
    "                if last_mse - mse > ep:\n",
    "                    last_mse = mse\n",
    "                    last_cost = cost\n",
    "                else:\n",
    "                    if not quiet:\n",
    "                        print(f\"Convergence after {iter_count} iterations: Cost = {cost}, Train MSE = {mse}\")\n",
    "                    break\n",
    "            # Check if cost is too high - sometimes the algorithm diverges\n",
    "            if mse > 5000:\n",
    "                theta, mse, cost = best_params\n",
    "                if not quiet:\n",
    "                    print(f\"Training MSE too high: Best Train MSE = {best_params[1]}\")\n",
    "                break\n",
    "        # If the iteration limit is reached, stop and return the best parameters\n",
    "        if iter_count > iter_limit:\n",
    "            theta, mse, cost = best_params\n",
    "            if not quiet:\n",
    "                print(f\"Iteration limit reached after {iter_count} iterations: Best Train MSE = {best_params[1]}\")\n",
    "            break\n",
    "\n",
    "    return (theta, cost, mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e6bab06-cf66-4dba-b68b-08b99b7d1fc4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Popularity-based Baseline\n",
    "#\n",
    "# Rank the items in the dataset based on popularity --> If the item is popular, predict 1, else 0\n",
    "\n",
    "def get_item_popularities(df, col):\n",
    "    # Define popularity: The items which have the highest playtime per person ratios weighted by number of plays\n",
    "    item_playCounts = df.groupby(\"item_id\").agg(\"sum\")[col]\n",
    "    item_playCountsBinary = df.groupby(\"item_id\").agg(\"sum\")[\"playtime_binary\"]\n",
    "    item_userCounts = df.groupby(\"item_id\").count()[\"user_id\"]\n",
    "\n",
    "    item_playsPerUser = (item_playCountsBinary / item_userCounts).sort_values(ascending=True)\n",
    "    # item_playsPerUser = (item_playCounts).sort_values(ascending=True)\n",
    "\n",
    "    return pd.DataFrame({\"pop_values\":item_playsPerUser, \"pop_sums\":item_playsPerUser.cumsum()})\n",
    "\n",
    "def get_most_popular_items(df, cutoff):\n",
    "    pop_cutoff = df[\"pop_values\"].max() * cutoff\n",
    "\n",
    "    return list(df[df[\"pop_values\"] > pop_cutoff].index)\n",
    "\n",
    "def predict_by_popularity(X, pop_items):\n",
    "    if isinstance(X, tuple):\n",
    "        if X[1] in pop_items: return 1\n",
    "        else: return 0\n",
    "    else:\n",
    "        output = pd.Series([0 for i in range(len(X))])\n",
    "        output[X[\"item_id\"].isin(pop_items)] = 1\n",
    "        return output\n",
    "\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71797786-1619-4ee2-9a2d-e01266368bf3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### OTHER HELPFUL FUNCTIONS\n",
    "######################################\n",
    "def get_rec_structs(train_data):\n",
    "    \"\"\"\n",
    "    Extract stats used for creating the classifier features\n",
    "    Input is (user_id, item_id, value), ...\n",
    "    Typically value is rating, but can be other things (e.g., hours played)\n",
    "\n",
    "    itemsPerUser: Records each item in the training set that each user interacted with (along with the corresponding value)\n",
    "    usersPerItem: Records each user in the training set that each item interacted with (along with the corresponding value)\n",
    "    valueDict: Records the value for each (user, item) tuple\n",
    "    userAverages: Gives the average value for each user\n",
    "    itemAverages: Gives the average value for each item\n",
    "    \"\"\"\n",
    "    ### Record which items each user interacted with and which users interacted with which item\n",
    "    itemsPerUser = defaultdict(list)\n",
    "    usersPerItem = defaultdict(list)\n",
    "    valueDict = {}\n",
    "    for u,b,v in train_data:\n",
    "        itemsPerUser[u].append((b,v))\n",
    "        usersPerItem[b].append((u,v))\n",
    "        valueDict[(u,b)] = v\n",
    "\n",
    "    ### Calculate user and item average ratings\n",
    "    userAverages = {}\n",
    "    itemAverages = {}\n",
    "    for u,tuples in itemsPerUser.items():\n",
    "        values = [value for item,value in tuples]\n",
    "        # values = [value for item,value in tuples if value != 0]\n",
    "        # if len(values) == 0: continue\n",
    "        userAverages[u] = sum(values) / len(values)\n",
    "    for i,tuples in usersPerItem.items():\n",
    "        values = [value for user,value in tuples]\n",
    "        # values = [value for user,value in tuples if value != 0]\n",
    "        # if len(values) == 0: continue\n",
    "        itemAverages[i] = sum(values) / len(values)\n",
    "\n",
    "    rec_structs = {\"itemsPerUser\":itemsPerUser,\n",
    "                  \"usersPerItem\":usersPerItem,\n",
    "                  \"valueDict\":valueDict,\n",
    "                  \"userAverages\":userAverages,\n",
    "                  \"itemAverages\":itemAverages,}\n",
    "\n",
    "    return rec_structs\n",
    "\n",
    "def unpack_rec_structs(rec_structs):\n",
    "    \"\"\"\n",
    "    Take the input recommender_structs and return the itemized contents\n",
    "    \"\"\"\n",
    "    itemsPerUser = rec_structs[\"itemsPerUser\"]\n",
    "    usersPerItem = rec_structs[\"usersPerItem\"]\n",
    "    valueDict = rec_structs[\"valueDict\"]\n",
    "    userAverages = rec_structs[\"userAverages\"]\n",
    "    itemAverages = rec_structs[\"itemAverages\"]\n",
    "\n",
    "    return (itemsPerUser, usersPerItem, valueDict, userAverages, itemAverages)\n",
    "\n",
    "### Functions to read files (From homework stubs)\n",
    "def readGz(path):\n",
    "    output = []\n",
    "    for l in gzip.open(path, mode = 'rt', encoding = \"utf-8\"):\n",
    "        output.append(eval(l))\n",
    "    return output\n",
    "\n",
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        u,b,r = l.strip().split(',')\n",
    "        r = int(r)\n",
    "        yield u,b,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7900934e-5f20-4f52-837d-f6fc1adce81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 281 ms\n",
      "Wall time: 292 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### PREPROCESS THE DATA\n",
    "seed = 100\n",
    "interaction_filepath = \"data/playtime_df.csv\"\n",
    "playtime_df = pd.read_csv(interaction_filepath).sample(frac=1, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dc0f3ef-c01d-4471-85ce-66c269fe3184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# rows in train_df: 541528\n",
      "# rows in valid_df: 135382\n",
      "# rows in train_df2: 676910\n",
      "# rows in test_df: 169227\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>playtime</th>\n",
       "      <th>recent_playtime</th>\n",
       "      <th>playtime_log</th>\n",
       "      <th>recent_playtime_log</th>\n",
       "      <th>playtime_binary</th>\n",
       "      <th>recent_playtime_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>169227.000000</td>\n",
       "      <td>169227.000000</td>\n",
       "      <td>169227.000000</td>\n",
       "      <td>169227.000000</td>\n",
       "      <td>169227.000000</td>\n",
       "      <td>169227.000000</td>\n",
       "      <td>169227.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>180278.419951</td>\n",
       "      <td>950.476951</td>\n",
       "      <td>8.591755</td>\n",
       "      <td>3.306487</td>\n",
       "      <td>0.110422</td>\n",
       "      <td>0.632245</td>\n",
       "      <td>0.026237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>132440.047426</td>\n",
       "      <td>5194.154759</td>\n",
       "      <td>139.282759</td>\n",
       "      <td>3.031033</td>\n",
       "      <td>0.744192</td>\n",
       "      <td>0.482196</td>\n",
       "      <td>0.159840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35140.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>214970.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>269390.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.831882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>530720.000000</td>\n",
       "      <td>361496.000000</td>\n",
       "      <td>16166.000000</td>\n",
       "      <td>12.798009</td>\n",
       "      <td>9.690727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             item_id       playtime  recent_playtime   playtime_log  \\\n",
       "count  169227.000000  169227.000000    169227.000000  169227.000000   \n",
       "mean   180278.419951     950.476951         8.591755       3.306487   \n",
       "std    132440.047426    5194.154759       139.282759       3.031033   \n",
       "min        10.000000       0.000000         0.000000       0.000000   \n",
       "25%     35140.000000       0.000000         0.000000       0.000000   \n",
       "50%    214970.000000      32.000000         0.000000       3.496508   \n",
       "75%    269390.000000     340.000000         0.000000       5.831882   \n",
       "max    530720.000000  361496.000000     16166.000000      12.798009   \n",
       "\n",
       "       recent_playtime_log  playtime_binary  recent_playtime_binary  \n",
       "count        169227.000000    169227.000000           169227.000000  \n",
       "mean              0.110422         0.632245                0.026237  \n",
       "std               0.744192         0.482196                0.159840  \n",
       "min               0.000000         0.000000                0.000000  \n",
       "25%               0.000000         0.000000                0.000000  \n",
       "50%               0.000000         1.000000                0.000000  \n",
       "75%               0.000000         1.000000                0.000000  \n",
       "max               9.690727         1.000000                1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train-test-validation\n",
    "n_interactions = len(playtime_df)\n",
    "train_df = playtime_df.sample(frac=0.8, random_state=seed).reset_index(drop=True)\n",
    "test_df = playtime_df[~playtime_df.index.isin(train_df.index)].reset_index(drop=True)\n",
    "valid_df = train_df.sample(frac=0.2, random_state=seed).reset_index(drop=True)\n",
    "train_df = train_df[~train_df.index.isin(valid_df.index)].reset_index(drop=True)\n",
    "train_df2 = pd.concat([train_df, valid_df], axis=0).reset_index(drop=True)\n",
    "\n",
    "print(f\"# rows in train_df: {len(train_df)}\")\n",
    "print(f\"# rows in valid_df: {len(valid_df)}\")\n",
    "print(f\"# rows in train_df2: {len(train_df2)}\")\n",
    "print(f\"# rows in test_df: {len(test_df)}\")\n",
    "\n",
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75bc0913-2428-412c-b502-f8c4338903bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save train/valid/train2/test dfs for other models\n",
    "train_df.to_csv(\"data/train_df.csv\", index=False)\n",
    "valid_df.to_csv(\"data/valid_df.csv\", index=False)\n",
    "train_df2.to_csv(\"data/train_df2.csv\", index=False)\n",
    "test_df.to_csv(\"data/test_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1f7135c-4928-4200-bfcd-f71d8948a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further split the data into X/y pairs for convenience\n",
    "class_col = \"playtime_binary\" # This what we want to predict\n",
    "X_train, y_train = train_df[[\"user_id\", \"item_id\"]], train_df[class_col]\n",
    "X_valid, y_valid = valid_df[[\"user_id\", \"item_id\"]], valid_df[class_col]\n",
    "X_test, y_test = test_df[[\"user_id\", \"item_id\"]], test_df[class_col]\n",
    "X_train2, y_train2 = train_df2[[\"user_id\", \"item_id\"]], train_df2[class_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15f5176a-5cde-4fbb-8aa3-9a2d2652db95",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_results = test_df[[\"user_id\", \"item_id\", \"playtime\", \"playtime_log\"]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ab5154-61d4-4217-8a9c-e628f2746e83",
   "metadata": {},
   "source": [
    "### BASELINE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74a72798-cadd-4d12-94b6-9775f03ae168",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c672bf8-2eb6-44be-9220-c468c7aff037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 19.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Always predict the mean\n",
    "playtime_cols = [\"playtime\", \"playtime_log\"]\n",
    "playtime_means = train_df2[playtime_cols].mean(axis=0)\n",
    "#Always predict the median\n",
    "playtime_medians = train_df2[playtime_cols].median(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e59ad581-4717-4aa3-a0a1-57178840184a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1.5 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>playtime</th>\n",
       "      <th>recent_playtime</th>\n",
       "      <th>playtime_log</th>\n",
       "      <th>recent_playtime_log</th>\n",
       "      <th>playtime_binary</th>\n",
       "      <th>recent_playtime_binary</th>\n",
       "      <th>playtime_mean_pred</th>\n",
       "      <th>playtimeLog_mean_pred</th>\n",
       "      <th>playtime_median_pred</th>\n",
       "      <th>playtimeLog_median_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u5084</td>\n",
       "      <td>31130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>969.703293</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u11861</td>\n",
       "      <td>233270</td>\n",
       "      <td>715</td>\n",
       "      <td>0</td>\n",
       "      <td>6.573680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>969.703293</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u4949</td>\n",
       "      <td>220200</td>\n",
       "      <td>232</td>\n",
       "      <td>0</td>\n",
       "      <td>5.451038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>969.703293</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u1808</td>\n",
       "      <td>4000</td>\n",
       "      <td>231</td>\n",
       "      <td>0</td>\n",
       "      <td>5.446737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>969.703293</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u5401</td>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>969.703293</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169222</th>\n",
       "      <td>u11442</td>\n",
       "      <td>238960</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>969.703293</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169223</th>\n",
       "      <td>u12710</td>\n",
       "      <td>4000</td>\n",
       "      <td>12936</td>\n",
       "      <td>5</td>\n",
       "      <td>9.467847</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>969.703293</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169224</th>\n",
       "      <td>u10496</td>\n",
       "      <td>8190</td>\n",
       "      <td>207</td>\n",
       "      <td>0</td>\n",
       "      <td>5.337538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>969.703293</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169225</th>\n",
       "      <td>u6112</td>\n",
       "      <td>48700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>969.703293</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169226</th>\n",
       "      <td>u1492</td>\n",
       "      <td>39000</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>4.110874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>969.703293</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169227 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  item_id  playtime  recent_playtime  playtime_log  \\\n",
       "0        u5084    31130         0                0      0.000000   \n",
       "1       u11861   233270       715                0      6.573680   \n",
       "2        u4949   220200       232                0      5.451038   \n",
       "3        u1808     4000       231                0      5.446737   \n",
       "4        u5401     1280         0                0      0.000000   \n",
       "...        ...      ...       ...              ...           ...   \n",
       "169222  u11442   238960        20                0      3.044522   \n",
       "169223  u12710     4000     12936                5      9.467847   \n",
       "169224  u10496     8190       207                0      5.337538   \n",
       "169225   u6112    48700         0                0      0.000000   \n",
       "169226   u1492    39000        60                0      4.110874   \n",
       "\n",
       "        recent_playtime_log  playtime_binary  recent_playtime_binary  \\\n",
       "0                  0.000000                0                       0   \n",
       "1                  0.000000                1                       0   \n",
       "2                  0.000000                1                       0   \n",
       "3                  0.000000                1                       0   \n",
       "4                  0.000000                0                       0   \n",
       "...                     ...              ...                     ...   \n",
       "169222             0.000000                1                       0   \n",
       "169223             1.791759                1                       1   \n",
       "169224             0.000000                1                       0   \n",
       "169225             0.000000                0                       0   \n",
       "169226             0.000000                1                       0   \n",
       "\n",
       "        playtime_mean_pred  playtimeLog_mean_pred  playtime_median_pred  \\\n",
       "0               969.703293                3.30626                  32.0   \n",
       "1               969.703293                3.30626                  32.0   \n",
       "2               969.703293                3.30626                  32.0   \n",
       "3               969.703293                3.30626                  32.0   \n",
       "4               969.703293                3.30626                  32.0   \n",
       "...                    ...                    ...                   ...   \n",
       "169222          969.703293                3.30626                  32.0   \n",
       "169223          969.703293                3.30626                  32.0   \n",
       "169224          969.703293                3.30626                  32.0   \n",
       "169225          969.703293                3.30626                  32.0   \n",
       "169226          969.703293                3.30626                  32.0   \n",
       "\n",
       "        playtimeLog_median_pred  \n",
       "0                      3.496508  \n",
       "1                      3.496508  \n",
       "2                      3.496508  \n",
       "3                      3.496508  \n",
       "4                      3.496508  \n",
       "...                         ...  \n",
       "169222                 3.496508  \n",
       "169223                 3.496508  \n",
       "169224                 3.496508  \n",
       "169225                 3.496508  \n",
       "169226                 3.496508  \n",
       "\n",
       "[169227 rows x 12 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Get predictions from the unscaled variables\n",
    "test_df[\"playtime_mean_pred\"] = playtime_means.loc[\"playtime\"]\n",
    "test_df[\"playtimeLog_mean_pred\"] = playtime_means.loc[\"playtime_log\"]\n",
    "\n",
    "test_df[\"playtime_median_pred\"] = playtime_medians.loc[\"playtime\"]\n",
    "test_df[\"playtimeLog_median_pred\"] = playtime_medians.loc[\"playtime_log\"]\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc0c9f64-3f78-4488-b28c-3d0b6d22bde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEANS\n",
      "MSE based on regular playtime scale: 26979453.8886885\n",
      "MSE based on regular playtime scale: 27833218.881216425\n",
      "MEDIANS\n",
      "MSE based on regular playtime scale: 27822684.146129165\n",
      "MSE based on regular playtime scale: 27822684.146129165\n"
     ]
    }
   ],
   "source": [
    "# Get MSE on regular playtime\n",
    "mse_playtime = get_MSE(test_df[\"playtime\"], test_df[\"playtime_mean_pred\"])\n",
    "mse_playtimeLog = get_MSE(test_df[\"playtime\"], np.exp(test_df[\"playtimeLog_mean_pred\"]) - 1)\n",
    "\n",
    "print(\"MEANS\")\n",
    "print(f\"MSE based on regular playtime scale: {mse_playtime}\")\n",
    "print(f\"MSE based on regular playtime scale: {mse_playtimeLog}\")\n",
    "\n",
    "# Get MSE on regular playtime\n",
    "mse_playtime = get_MSE(test_df[\"playtime\"], test_df[\"playtime_median_pred\"])\n",
    "mse_playtimeLog = get_MSE(test_df[\"playtime\"], np.exp(test_df[\"playtimeLog_median_pred\"]) - 1)\n",
    "\n",
    "print(\"MEDIANS\")\n",
    "print(f\"MSE based on regular playtime scale: {mse_playtime}\")\n",
    "print(f\"MSE based on regular playtime scale: {mse_playtimeLog}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8e6379e-baed-4d52-ab51-6187a1bcb5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEANS\n",
      "MSE based on log playtime scale: 21.94296292972277\n",
      "MSE based on log playtime scale: 9.187107397527571\n",
      "MEDIANS\n",
      "MSE based on log playtime scale: 9.223215240818883\n",
      "MSE based on log playtime scale: 9.223215240818883\n"
     ]
    }
   ],
   "source": [
    "# Get MSE on log playtime\n",
    "mse_playtime2 = get_MSE(test_df[\"playtime_log\"], np.log(test_df[\"playtime_mean_pred\"] + 1))\n",
    "mse_playtimeLog2 = get_MSE(test_df[\"playtime_log\"], test_df[\"playtimeLog_mean_pred\"])\n",
    "\n",
    "print(\"MEANS\")\n",
    "print(f\"MSE based on log playtime scale: {mse_playtime2}\")\n",
    "print(f\"MSE based on log playtime scale: {mse_playtimeLog2}\")\n",
    "\n",
    "# Get MSE on log playtime\n",
    "mse_playtime2 = get_MSE(test_df[\"playtime_log\"], np.log(test_df[\"playtime_median_pred\"] + 1))\n",
    "mse_playtimeLog2 = get_MSE(test_df[\"playtime_log\"], test_df[\"playtimeLog_median_pred\"])\n",
    "\n",
    "print(\"MEDIANS\")\n",
    "print(f\"MSE based on log playtime scale: {mse_playtime2}\")\n",
    "print(f\"MSE based on log playtime scale: {mse_playtimeLog2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e630bde-dff1-4dd6-a37d-77d99302b67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEANS\n",
      "MAE based on regular playtime scale: 1446.5152666476665\n",
      "MAE based on regular playtime scale: 947.326055480168\n",
      "MEDIANS\n",
      "MAE based on regular playtime scale: 947.2356125204607\n",
      "MAE based on regular playtime scale: 947.2356125204607\n"
     ]
    }
   ],
   "source": [
    "# Get MAE on regular playtime\n",
    "mae_playtime = get_MAE(test_df[\"playtime\"], test_df[\"playtime_mean_pred\"])\n",
    "mae_playtimeLog = get_MAE(test_df[\"playtime\"], np.exp(test_df[\"playtimeLog_mean_pred\"]) - 1)\n",
    "\n",
    "print(\"MEANS\")\n",
    "print(f\"MAE based on regular playtime scale: {mae_playtime}\")\n",
    "print(f\"MAE based on regular playtime scale: {mae_playtimeLog}\")\n",
    "\n",
    "# Get MAE on regular playtime\n",
    "mae_playtime = get_MAE(test_df[\"playtime\"], test_df[\"playtime_median_pred\"])\n",
    "mae_playtimeLog = get_MAE(test_df[\"playtime\"], np.exp(test_df[\"playtimeLog_median_pred\"]) - 1)\n",
    "\n",
    "print(\"MEDIANS\")\n",
    "print(f\"MAE based on regular playtime scale: {mae_playtime}\")\n",
    "print(f\"MAE based on regular playtime scale: {mae_playtimeLog}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56db67e1-1101-4598-bdf5-bceae8cd586b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEANS\n",
      "MAE based on regular playtime scale: 3.893728328812909\n",
      "MAE based on regular playtime scale: 2.7169138908933355\n",
      "MEDIANS\n",
      "MAE based on regular playtime scale: 2.713820254040632\n",
      "MAE based on regular playtime scale: 2.713820254040632\n"
     ]
    }
   ],
   "source": [
    "# Get MSE on log playtime\n",
    "mae_playtime2 = get_MAE(test_df[\"playtime_log\"], np.log(test_df[\"playtime_mean_pred\"] + 1))\n",
    "mae_playtimeLog2 = get_MAE(test_df[\"playtime_log\"], test_df[\"playtimeLog_mean_pred\"])\n",
    "\n",
    "print(\"MEANS\")\n",
    "print(f\"MAE based on regular playtime scale: {mae_playtime2}\")\n",
    "print(f\"MAE based on regular playtime scale: {mae_playtimeLog2}\")\n",
    "\n",
    "# Get MSE on log playtime\n",
    "mae_playtime2 = get_MAE(test_df[\"playtime_log\"], np.log(test_df[\"playtime_median_pred\"] + 1))\n",
    "mae_playtimeLog2 = get_MAE(test_df[\"playtime_log\"], test_df[\"playtimeLog_median_pred\"])\n",
    "\n",
    "print(\"MEDIANS\")\n",
    "print(f\"MAE based on regular playtime scale: {mae_playtime2}\")\n",
    "print(f\"MAE based on regular playtime scale: {mae_playtimeLog2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee2b8891-eb62-47a0-a6be-38493edd8bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed to train model = 0.0 min and 0.3052687644958496s (0.3052687644958496s)\n"
     ]
    }
   ],
   "source": [
    "t_elapsed = time.time() - t0\n",
    "print(f\"Time elapsed to train model = {t_elapsed // 60} min and {t_elapsed % 60}s ({t_elapsed}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc6458d6-84af-4eca-ba08-94c8d0f0828d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>playtime</th>\n",
       "      <th>recent_playtime</th>\n",
       "      <th>playtime_log</th>\n",
       "      <th>recent_playtime_log</th>\n",
       "      <th>playtime_binary</th>\n",
       "      <th>recent_playtime_binary</th>\n",
       "      <th>playtime_mean_pred</th>\n",
       "      <th>playtimeLog_mean_pred</th>\n",
       "      <th>playtime_median_pred</th>\n",
       "      <th>playtimeLog_median_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u5084</td>\n",
       "      <td>31130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>969.703293</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u11861</td>\n",
       "      <td>233270</td>\n",
       "      <td>715</td>\n",
       "      <td>0</td>\n",
       "      <td>6.573680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>969.703293</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u4949</td>\n",
       "      <td>220200</td>\n",
       "      <td>232</td>\n",
       "      <td>0</td>\n",
       "      <td>5.451038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>969.703293</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u1808</td>\n",
       "      <td>4000</td>\n",
       "      <td>231</td>\n",
       "      <td>0</td>\n",
       "      <td>5.446737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>969.703293</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u5401</td>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>969.703293</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169222</th>\n",
       "      <td>u11442</td>\n",
       "      <td>238960</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>969.703293</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169223</th>\n",
       "      <td>u12710</td>\n",
       "      <td>4000</td>\n",
       "      <td>12936</td>\n",
       "      <td>5</td>\n",
       "      <td>9.467847</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>969.703293</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169224</th>\n",
       "      <td>u10496</td>\n",
       "      <td>8190</td>\n",
       "      <td>207</td>\n",
       "      <td>0</td>\n",
       "      <td>5.337538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>969.703293</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169225</th>\n",
       "      <td>u6112</td>\n",
       "      <td>48700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>969.703293</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169226</th>\n",
       "      <td>u1492</td>\n",
       "      <td>39000</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>4.110874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>969.703293</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169227 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  item_id  playtime  recent_playtime  playtime_log  \\\n",
       "0        u5084    31130         0                0      0.000000   \n",
       "1       u11861   233270       715                0      6.573680   \n",
       "2        u4949   220200       232                0      5.451038   \n",
       "3        u1808     4000       231                0      5.446737   \n",
       "4        u5401     1280         0                0      0.000000   \n",
       "...        ...      ...       ...              ...           ...   \n",
       "169222  u11442   238960        20                0      3.044522   \n",
       "169223  u12710     4000     12936                5      9.467847   \n",
       "169224  u10496     8190       207                0      5.337538   \n",
       "169225   u6112    48700         0                0      0.000000   \n",
       "169226   u1492    39000        60                0      4.110874   \n",
       "\n",
       "        recent_playtime_log  playtime_binary  recent_playtime_binary  \\\n",
       "0                  0.000000                0                       0   \n",
       "1                  0.000000                1                       0   \n",
       "2                  0.000000                1                       0   \n",
       "3                  0.000000                1                       0   \n",
       "4                  0.000000                0                       0   \n",
       "...                     ...              ...                     ...   \n",
       "169222             0.000000                1                       0   \n",
       "169223             1.791759                1                       1   \n",
       "169224             0.000000                1                       0   \n",
       "169225             0.000000                0                       0   \n",
       "169226             0.000000                1                       0   \n",
       "\n",
       "        playtime_mean_pred  playtimeLog_mean_pred  playtime_median_pred  \\\n",
       "0               969.703293                3.30626                  32.0   \n",
       "1               969.703293                3.30626                  32.0   \n",
       "2               969.703293                3.30626                  32.0   \n",
       "3               969.703293                3.30626                  32.0   \n",
       "4               969.703293                3.30626                  32.0   \n",
       "...                    ...                    ...                   ...   \n",
       "169222          969.703293                3.30626                  32.0   \n",
       "169223          969.703293                3.30626                  32.0   \n",
       "169224          969.703293                3.30626                  32.0   \n",
       "169225          969.703293                3.30626                  32.0   \n",
       "169226          969.703293                3.30626                  32.0   \n",
       "\n",
       "        playtimeLog_median_pred  \n",
       "0                      3.496508  \n",
       "1                      3.496508  \n",
       "2                      3.496508  \n",
       "3                      3.496508  \n",
       "4                      3.496508  \n",
       "...                         ...  \n",
       "169222                 3.496508  \n",
       "169223                 3.496508  \n",
       "169224                 3.496508  \n",
       "169225                 3.496508  \n",
       "169226                 3.496508  \n",
       "\n",
       "[169227 rows x 12 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "090ff8e5-f768-454a-8d0e-32b1bc69fbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>playtime</th>\n",
       "      <th>playtime_log</th>\n",
       "      <th>baseline_mean_pred</th>\n",
       "      <th>baseline_median_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u5084</td>\n",
       "      <td>31130</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u11861</td>\n",
       "      <td>233270</td>\n",
       "      <td>715</td>\n",
       "      <td>6.573680</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u4949</td>\n",
       "      <td>220200</td>\n",
       "      <td>232</td>\n",
       "      <td>5.451038</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u1808</td>\n",
       "      <td>4000</td>\n",
       "      <td>231</td>\n",
       "      <td>5.446737</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u5401</td>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169222</th>\n",
       "      <td>u11442</td>\n",
       "      <td>238960</td>\n",
       "      <td>20</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169223</th>\n",
       "      <td>u12710</td>\n",
       "      <td>4000</td>\n",
       "      <td>12936</td>\n",
       "      <td>9.467847</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169224</th>\n",
       "      <td>u10496</td>\n",
       "      <td>8190</td>\n",
       "      <td>207</td>\n",
       "      <td>5.337538</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169225</th>\n",
       "      <td>u6112</td>\n",
       "      <td>48700</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169226</th>\n",
       "      <td>u1492</td>\n",
       "      <td>39000</td>\n",
       "      <td>60</td>\n",
       "      <td>4.110874</td>\n",
       "      <td>3.30626</td>\n",
       "      <td>3.496508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169227 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  item_id  playtime  playtime_log  baseline_mean_pred  \\\n",
       "0        u5084    31130         0      0.000000             3.30626   \n",
       "1       u11861   233270       715      6.573680             3.30626   \n",
       "2        u4949   220200       232      5.451038             3.30626   \n",
       "3        u1808     4000       231      5.446737             3.30626   \n",
       "4        u5401     1280         0      0.000000             3.30626   \n",
       "...        ...      ...       ...           ...                 ...   \n",
       "169222  u11442   238960        20      3.044522             3.30626   \n",
       "169223  u12710     4000     12936      9.467847             3.30626   \n",
       "169224  u10496     8190       207      5.337538             3.30626   \n",
       "169225   u6112    48700         0      0.000000             3.30626   \n",
       "169226   u1492    39000        60      4.110874             3.30626   \n",
       "\n",
       "        baseline_median_pred  \n",
       "0                   3.496508  \n",
       "1                   3.496508  \n",
       "2                   3.496508  \n",
       "3                   3.496508  \n",
       "4                   3.496508  \n",
       "...                      ...  \n",
       "169222              3.496508  \n",
       "169223              3.496508  \n",
       "169224              3.496508  \n",
       "169225              3.496508  \n",
       "169226              3.496508  \n",
       "\n",
       "[169227 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the one with the best results\n",
    "test_df_results[\"baseline_mean_pred\"] = test_df[\"playtimeLog_mean_pred\"]\n",
    "test_df_results[\"baseline_median_pred\"] = test_df[\"playtimeLog_median_pred\"]\n",
    "\n",
    "test_df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b534f46-8e2d-4ff9-866e-f1692275d7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_results.to_csv(\"data/test_results_baseline.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
